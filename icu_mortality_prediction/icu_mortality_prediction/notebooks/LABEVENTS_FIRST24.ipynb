{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import psycopg2\n",
    "from scipy.stats import ks_2samp\n",
    "import scipy.stats as scats\n",
    "# import visuals as vs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from heapq import nlargest\n",
    "plt.style.use('ggplot') \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from icu_mortality_prediction import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-III Critical Care Database\n",
    "\n",
    "MIMIC-III (Medical Information Mart for Intensive Care III) is a large, freely-available database comprising deidentified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012.\n",
    "\n",
    "The database includes information such as demographics, vital sign measurements made at the bedside (~1 data point per hour), laboratory test results, procedures, medications, caregiver notes, imaging reports, and mortality (both in and out of hospital).\n",
    "\n",
    "MIMIC supports a diverse range of analytic studies spanning epidemiology, clinical decision-rule improvement, and electronic tool development. It is notable for three factors:\n",
    "\n",
    "it is freely available to researchers worldwide\n",
    "it encompasses a diverse and very large population of ICU patients\n",
    "it contains high temporal resolution data including lab results, electronic documentation, and bedside monitor trends and waveforms.\n",
    "\n",
    "Citations: \n",
    "MIMIC-III, a freely accessible critical care database. Johnson AEW, Pollard TJ, Shen L, Lehman L, Feng M, Ghassemi M, Moody B, Szolovits P, Celi LA, and Mark RG. Scientific Data (2016). DOI: 10.1038/sdata.2016.35. Available at: http://www.nature.com/articles/sdata201635\n",
    "\n",
    "Pollard, T. J. & Johnson, A. E. W. The MIMIC-III Clinical Database http://dx.doi.org/10.13026/C2XW26 (2016).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LAB DATA\n",
    "The mimic III database was downloaded and reconstructed locally using posgresql. The database was managed graphically using Portico. \n",
    "A query was run on the mimic III database to generate chart data for the first 24hrs of a patients icu stay as well as demographic data for patients diagnosed with sepsis according to the Angus criteria. \n",
    "(Angus et al, 2001. Epidemiology of severe sepsis in the United States; http://www.ncbi.nlm.nih.gov/pubmed/11445675 )\n",
    "\n",
    "The query was exported from Porticoto the file LAB_EVENTS_ANGUS_FIRST24.csv. The data was read into a pandas dataframe lab_events. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_raw_df = pd.read_csv(os.path.join(DATA_DIR, 'raw','D_LABITEMS.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_raw_df[lab_events_raw_df['LABEL']=='pH'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_events_filename = 'LAB_EVENTS_FIRST24.csv'\n",
    "lab_events_filepath = os.path.join(DATA_DIR, 'interim',lab_events_filename)\n",
    "lab_events_data_df = pd.read_csv(lab_events_filepath) #, index_col = 'icustay_id')\n",
    "\n",
    "lab_events_data_df.loc[:,'charttime']  = pd.to_datetime(lab_events_data_df.loc[:,'charttime'])\n",
    "lab_events_data_df = lab_events_data_df.sort_values(['icustay_id', 'charttime'],ascending=True)\n",
    "# lab_events_data_df.drop(['charttime'], axis=1, inplace=True)\n",
    "lab_events_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates column name variables. \n",
    "lab_value = 'valuenum'\n",
    "lab_label = 'label'\n",
    "gender = 'gender'\n",
    "label = 'label'\n",
    "valuenum = 'valuenum'\n",
    "hospital_expire_flag = 'hospital_expire_flag'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates copy of the lab_events_data_df dataframe for visualization exploration\n",
    "aggregate_lab_values_for_visualization_df = lab_events_data_df[[gender, \n",
    "                                                             hospital_expire_flag, \n",
    "                                                            label, \n",
    "                                                            valuenum]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates counts for different types of lab measurements\n",
    "lab_measurement_type_counts = lab_events_data_df['label'].value_counts()\n",
    "\n",
    "\n",
    "lab_measurement_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lab measurement types with counts greater than 5k. \n",
    "# Removes sparse lab values. \n",
    "lab_measurement_types = list(lab_measurement_type_counts[\n",
    "                                        lab_measurement_type_counts>5000\n",
    "                                                        ].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_measurement_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Distributions for All Lab Measurements By Gender and Survivor Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gender_survivor_cohorts(lab_events_data_df, gend='F', expired=True):\n",
    "    gender_survivor_cohort_df = lab_events_data_df[\n",
    "                                 (lab_events_data_df[label]==lab_measurement)&             \n",
    "                                 (lab_events_data_df[hospital_expire_flag]==expired)& \n",
    "                                 (lab_events_data_df[gender] == gend)\n",
    "                                ]\n",
    "    if gend==1:\n",
    "        gender_survivor_cohort_df.name = 'Survivors'\n",
    "    else:\n",
    "        gender_survivor_cohort_df.name = 'Non_Survivors'\n",
    "    return gender_survivor_cohort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gender_survivor_lab_values_distributions(survivors, non_survivors, lab_value):    \n",
    "    plt.subplots(figsize=(10,4))\n",
    "    survivors[lab_value].plot.hist(\n",
    "                                bins=100, \n",
    "                                alpha=1.0,\n",
    "                                label='Survival'\n",
    "    )\n",
    "\n",
    "    non_survivors[lab_value].plot.hist(\n",
    "                                bins=100,\n",
    "                                alpha=1.0,\n",
    "                                label='Non-Survivors')\n",
    "    # add title, labels etc.\n",
    "    plt.title('{} measurement on ICU admission'.format(lab_measurement) + \n",
    "               'vs ICU mortality by gender = {}\\n'.format(gend))\n",
    "    plt.xlabel(lab_measurement)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(.75,.75),fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_values = ['M', 'F']\n",
    "\n",
    "for lab_measurement in lab_measurement_types:\n",
    "\n",
    "    for gend in gender_values:\n",
    "     \n",
    "        \n",
    "        #print gend\n",
    "        non_survivors = generate_gender_survivor_cohorts(lab_events_data_df, gend, expired=True)\n",
    "        \n",
    "        survivors = generate_gender_survivor_cohorts(lab_events_data_df, gend, expired=False)\n",
    "        plot_gender_survivor_lab_values_distributions(survivors, non_survivors, lab_value)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Lab Measurement Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lab_value_distribution(lab_values_series, xlimits=None, bins=500):\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(14,4))\n",
    "    lab_values_series.plot.hist(\n",
    "                            ax=axes[0],\n",
    "                            bins=bins, \n",
    "                            title=lab_values_series.name + ' Distribution'\n",
    "    )\n",
    "    if xlimits:\n",
    "        axes[0].set_xlim(xlimits)\n",
    "    ax = lab_values_series.plot.hist(\n",
    "                            ax=axes[1],\n",
    "                            bins=bins, \n",
    "                            logx=True,\n",
    "                            title=lab_values_series.name + ' Log Distribution'\n",
    "    \n",
    "    )\n",
    "    plt.xlabel(\"Log Scale\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lab_value_series(lab_values_df, lab_measurement):\n",
    "\n",
    "    lab_values_series = lab_values_df[\n",
    "                                    lab_values_df['label']== lab_measurement\n",
    "                                    ]['valuenum']\n",
    "    lab_values_series.name = lab_measurement\n",
    "    return lab_values_series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histogram_frequency_counts(lab_values_series, bins=1000):\n",
    "    #returns non-zero frequency counts\n",
    "    count, division = np.histogram(lab_values_series.dropna(), bins=bins)\n",
    "    histogram_frequency_counts_series = pd.Series(count, division[:-1])\n",
    "    non_zero_histogram_frequency_counts_series = histogram_frequency_counts_series[\n",
    "                                                    histogram_frequency_counts_series>0\n",
    "    ]\n",
    "    return non_zero_histogram_frequency_counts_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "pH_values_series = generate_lab_value_series(lab_events_data_df, 'pH')\n",
    "\n",
    "visualize_lab_value_distribution(pH_values_series) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing values above 8 and below 6.5\n",
    "Evidence to date supports the assumption that pH values outside this range are incompatible with life. \n",
    "Values outside this range also appear to occur in whole integers which leads to the conclusion that \n",
    "these are errors and not continuous measurements. \n",
    "\n",
    "\n",
    "Normal cellular metabolism and function require that blood pH be maintained within narrow limits, \n",
    "7.35-7.45. Even mild excursion outside this range has deleterious effect, \n",
    "and pH of less than 6.8 or greater than 7.8 is considered – according to medical and physiology texts – \n",
    "incompatible with life. \n",
    "Such a view is challenged by the detail of a recently published case report, \n",
    "which describes survival of a patient whose pH was just 6.53\n",
    "https://acutecaretesting.org/en/journal-scans/record-breaking-blood-ph-survival-following-extreme-acidosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on a predefined scale\n",
    "visualize_lab_value_distribution(pH_values_series, [6.5, 8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_frequency_counts_series = generate_histogram_frequency_counts(pH_values_series, bins=1000)\n",
    "\n",
    "# View frequency counts\n",
    "print(ph_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START DEV CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-16de46bc264a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-16de46bc264a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    replace_em = lambda x: x['A'] if ((x['C']=='a')&((x['A']>=2)&(x['A']<=4)) else np.nan\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "replace_em = lambda x: x['A'] if ((x['C']=='a')&((x['A']>=2)&(x['A']<=4)) else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[0,1,'a'], \n",
    "                   [2,3,'a'], \n",
    "                   [4,5,'a'], \n",
    "                   [6,7,'c'], \n",
    "                   [8,9,'c']], columns = ['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  0  1  a\n",
       "1  2  3  a\n",
       "2  4  5  a\n",
       "3  6  7  c\n",
       "4  8  9  c"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  B  C\n",
       "0  NaN  1  a\n",
       "1  NaN  3  a\n",
       "2  4.0  5  a\n",
       "3  NaN  7  c\n",
       "4  NaN  9  c"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A'] = df.apply(replace_em, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A','C']].apply(replace_em, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (df[['A','B']]<2)&(df['C']=='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mask(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (df[['A','B']]<2)|(df[['A','B']]>4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df['C'=='a')&((df[['A','B']]>=2)&(df[['A','B']]<=4)) #(df>=2)&(df<=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['C']=='a'][['A','B']].where(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A','B']].where(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A','B']].mask(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['C']=='a'][['A','B']].mask(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['C']=='a'][['A','B']] = df[df['C']=='a'][['A','B']].mask(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = df % 3 == 0\n",
    "\n",
    "df.mask(m)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = df % 3 == 0\n",
    "\n",
    "df.where(n)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(m, -df) == np.where(m, df, -df)\n",
    "      A     B\n",
    "0  True  True\n",
    "1  True  True\n",
    "2  True  True\n",
    "3  True  True\n",
    "4  True  True\n",
    "df.where(m, -df) == df.mask(~m, -df)\n",
    "      A     B\n",
    "0  True  True\n",
    "1  True  True\n",
    "2  True  True\n",
    "3  True  True\n",
    "4  True  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = lab_events_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['label']=='pH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP DEV CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Blood Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "wbc_values_series = generate_lab_value_series(lab_events_data_df, 'White Blood Cells')\n",
    "\n",
    "visualize_lab_value_distribution(wbc_values_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on a predefined scale\n",
    "visualize_lab_value_distribution(wbc_values_series, [0,60]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc_frequency_counts_series = generate_histogram_frequency_counts(wbc_values_series, bins=1000)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(wbc_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am unaware of any upper possible limit on WBC counts. \n",
    "In the absence of that, the tail appears to include a number of high measurements and does not appear to result from a single \n",
    "erroneous value. Its therefore concluded there's insufficient evidence to conclude the values are outliers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "creatinine_values_series = generate_lab_value_series(lab_events_data_df, 'Creatinine')\n",
    "\n",
    "visualize_lab_value_distribution(creatinine_values_series) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatinine appears to follow a log-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on a predefined scale\n",
    "visualize_lab_value_distribution(creatinine_values_series, [0,13]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatinine_frequency_counts_series = generate_histogram_frequency_counts(creatinine_values_series, bins=1000)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(creatinine_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest peak creatinine level observed as of 2013 was 53.9. The long tail observed here is therefore\n",
    "within the range of observed values. \n",
    "\n",
    "https://www.researchgate.net/publication/273742614_A_Surviving_Patient_with_Record_High_Creatinine#:~:text=A%20literature%20search%20indicates%20that,in%20the%20literature%20%5B3%5D%20.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "glucose_values_series = generate_lab_value_series(lab_events_data_df, 'Glucose')\n",
    "\n",
    "visualize_lab_value_distribution(glucose_values_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on a predefined scale\n",
    "visualize_lab_value_distribution(glucose_values_series, [0,750]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glucose appears to follow a log-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose_frequency_counts_series = generate_histogram_frequency_counts(glucose_values_series, bins=1000)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(glucose_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest recorded blood glucose measurement as of 2001 was 2,656. \n",
    "The long tail observed here is therefore within the range of observed values. \n",
    "\n",
    "Michael Patrick Buonocore (USA) (b. 19 May 2001), survived a blood sugar level of 147.6 mmol/L (2,656 mg/dl) when admitted \n",
    "to the Pocono Emergency Room in East Stroudsburg, Pennsylvania, USA, on 23 March 2008. The normal blood sugar range is \n",
    "between 4.4 to 6.6 mmol/L (80-120 mg/dl).\n",
    "\n",
    "https://www.guinnessworldrecords.com/world-records/highest-blood-sugar-level/?fb_comment_id=811257658947726_974655159274641#:~:text=Michael%20Patrick%20Buonocore%20(USA)%20(,%2D120%20mg%2Fdl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lactate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "lactate_values_series = generate_lab_value_series(lab_events_data_df, 'Lactate')\n",
    "\n",
    "visualize_lab_value_distribution(lactate_values_series) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lactate appears to follow a log-normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxygen Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_measurement_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "oxygen_values_series = generate_lab_value_series(lab_events_data_df, 'Oxygen Saturation')\n",
    "\n",
    "visualize_lab_value_distribution(oxygen_values_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Oxygen Saturation is a percent value and can't be above 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on a predefined scale\n",
    "oxygen_values_series = oxygen_values_series[oxygen_values_series<=100]\n",
    "visualize_lab_value_distribution(oxygen_values_series) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glucose appears to follow a non-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_frequency_counts_series = generate_histogram_frequency_counts(oxygen_values_series, bins=100)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(oxygen_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lactate Dehydrogenase (LD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_measurement_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "ld_values_series = generate_lab_value_series(lab_events_data_df, 'Lactate Dehydrogenase (LD)')\n",
    "\n",
    "visualize_lab_value_distribution(ld_values_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "ld_values_series = generate_lab_value_series(aggregate_lab_values_for_visualization_df, 'Lactate Dehydrogenase (LD)')\n",
    "\n",
    "visualize_lab_value_distribution(ld_values_series, [0,6000], bins=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lactate Dehydrogenase appears to follow a Log-Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_frequency_counts_series = generate_histogram_frequency_counts(ld_values_series, bins=100)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(ld_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creatinine, Urine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw values on normal and log scale\n",
    "urine_creatinine_values_series = generate_lab_value_series(lab_events_data_df, 'Creatinine, Urine')\n",
    "\n",
    "visualize_lab_value_distribution(urine_creatinine_values_series, bins=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urine Creatinine appears to follow a right-skewed normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_creatinine_frequency_counts_series = generate_histogram_frequency_counts(urine_creatinine_values_series, bins=100)\n",
    "\n",
    "# View frequency counts to see if the long tails are outliers or just very high numbers\n",
    "print(urine_creatinine_frequency_counts_series.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorganizing the data\n",
    "The imported data uses subject_id as the index. The following code moves the subject_id data to a column, creates\n",
    "a proper index and reorganizes the columns to have the lab results grouped together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print(\"loading lab data\")\n",
    "# lab_events_data_df['subject_id'] = lab_events_data_df.index\n",
    "# lab_events_data_df.set_index(np.arange(lab_events_data_df.shape[0]), inplace = True)\n",
    "# cols = list(lab_events_data_df.columns)\n",
    "# cols.insert(0, cols.pop(cols.index('icustay_id')))\n",
    "# cols.insert(1, cols.pop(cols.index('subject_id')))\n",
    "# lab_events_data_df = lab_events_data_df[cols]\n",
    "# print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique_icu_stay_count = lab_events_data_df.drop_duplicates('icustay_id', keep = 'first').shape[0]\n",
    "unique_patients_count = lab_events_data_df.drop_duplicates('subject_id', keep = 'first').shape[0]\n",
    "\n",
    "print(\"The number of unique ICU stays = {}\".format(unique_icu_stay_count))\n",
    "print(\"The number of unique patients  = {}\\n\".format(unique_patients_count))\n",
    "\n",
    "# display the different measurements captured in the database query\n",
    "labels = lab_events_data_df.label.unique()\n",
    "print(\"Lab measurements inlcude/n\")\n",
    "print(labels)\n",
    "# display(lab_events_data_df.shape)\n",
    "print(\"Example lab values for Lactate:\")\n",
    "display(lab_events_data_df[(lab_events_data_df.label=='Lactate') & (~(lab_events_data_df.valuenum.isnull()))].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Feature Prevalence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG START "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_pivot_df[~test_merged_pivot_df['Hematocrit'].isna()][['icustay_id','Hematocrit']].groupby('icustay_id').first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# REMOVE VARIABLES FOR WHICH THERE IS LITTLE DATA / FEW ICUSTAYS FOR WHICH DATA WAS RECORDED\n",
    "labels2 = []\n",
    "\n",
    "for item in labels:\n",
    "    lab_count = lab_events_data_df['icustay_id'][lab_events_data_df['label'] == item].dropna().unique().shape[0]\n",
    "    #num_measures = data[data.label == item][['icustay_id', 'label']].dropna().groupby('icustay_id').count()\n",
    "    print(\"{}    {}\".format(item, lab_count)) #, num_measures)\n",
    "    if lab_count > 6000:\n",
    "        print(\"adding {}\".format(item))\n",
    "        labels2.append(item)\n",
    "labels2.sort(key=str.lower)\n",
    "labels2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATE NUMBER OF SAMPLES FOR EACH FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the number of samples taken in 24 hours for each measurement\n",
    "item = labels2[0]\n",
    "\n",
    "lab_counts_df =  lab_events_data_df[lab_events_data_df['label'] == item][['icustay_id', 'label']].dropna().groupby('icustay_id').count()\n",
    "   \n",
    "for item in labels2[1:]:\n",
    "    #num_samps = data['icustay_id'][data.label == item].dropna().unique().shape[0]\n",
    "    groupby_counts = lab_events_data_df[lab_events_data_df['label'] == item][['icustay_id', 'label']].dropna().groupby('icustay_id').count()\n",
    "    groupby_counts.columns = [item]\n",
    "    lab_counts_df = lab_counts_df.merge(groupby_counts,left_index = True, right_index = True, how = 'left', sort = True) \n",
    "    #print \"{}    {}\".format(item, num_measures) #, num_measures)\n",
    "\n",
    "#num_samps_df.drop('label', axis=1, inplace = True)\n",
    "lab_counts_df.dropna().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE COLORMAPS SHOWING PATTERNS OF MISSING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# DISPLAY COLORMAP OF MISSING SAMPLES FOR EACH VARIABLE\n",
    "# REFERRING TO THIS AS AN AFFINITY MAP, SHOWING WHICH DATA WAS COLLECTED MOST OFTEN TOGETHER. \n",
    "# ASSIGNING NaN A POSITIVE VALUE MAKES MISSING DATA APPEAR BRIGHT YELLOW\n",
    "\n",
    "lab_count_map_df = lab_counts_df.copy()\n",
    "lab_count_map_df.drop(['label'], axis=1, inplace=True)\n",
    "for col in lab_count_map_df.columns:\n",
    "        lab_count_map_df[col] = lab_count_map_df[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        \n",
    "\n",
    "# lab_count_map_df = lab_count_map_df.sort_values(by ='Oxygen Saturation', axis = 0, ascending = True)\n",
    "plt.rc('font', size=15)   \n",
    "plt.figure(figsize= (25,15))\n",
    "plt.pcolor(lab_count_map_df)\n",
    "#ax.set_ylim([0.0,missing.shape[0]])\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(0.5, len(lab_count_map_df.columns), 1), lab_count_map_df.columns)\n",
    "plt.xticks(rotation = 30, ha = 'right')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Calculating values from original data including mean, std, delta etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# height and weight are left out from the calculated measures because there was only one\n",
    "# measurement so they are constant.\n",
    "\n",
    "# creates dicts of new feature names with the lab label as entries\n",
    "# this will help in traversing columns and calculating new features\n",
    "\n",
    "# labels2 were sorted alphabetically so we order this list accordingly before zipping\n",
    "dict_names = ['Creat','CreatUrine', 'Gluc', 'Hemat', 'Lac', 'LacDehyd', 'O2sat', 'pH', 'WBC']\n",
    "\n",
    "first_dict_names = dict(zip([item + '_first' for item in dict_names], labels2))\n",
    "mean_dict_names = dict(zip([item + '_mean' for item in dict_names], labels2))\n",
    "med_dict_names = dict(zip([item + '_med' for item in dict_names], labels2))\n",
    "std_dict_names = dict(zip([item + '_std' for item in dict_names], labels2))\n",
    "skew_dict_names = dict(zip([item + '_skew' for item in dict_names], labels2))\n",
    "min_dict_names = dict(zip([item + '_min' for item in dict_names], labels2))\n",
    "max_dict_names = dict(zip([item + '_max' for item in dict_names], labels2))\n",
    "slope_dict_names = dict(zip([item + '_slope' for item in dict_names], labels2))\n",
    "delta_dict_names = dict(zip([item + '_delta' for item in dict_names], labels2))\n",
    "abnflag_dict_names = dict(zip([item + '_abnflag' for item in dict_names], labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dict_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# creates list of name_dicts\n",
    "names_list = [first_dict_names, mean_dict_names, med_dict_names, std_dict_names, skew_dict_names, \n",
    "              min_dict_names, max_dict_names, slope_dict_names, delta_dict_names, abnflag_dict_names ]\n",
    "# create list of zipping into dictionary the measurement type and \n",
    "# corresponding names dict \n",
    "calc_list = ['first', 'mean', 'med', 'std', 'skew', 'min', 'max', 'slope', 'delta', 'abnflag']\n",
    "\n",
    "# create dictionary where the key is the feature type (calculation\n",
    "# and the value is the appropriate names dicts\n",
    "names_dict = dict(zip(calc_list, names_list))\n",
    "\n",
    "\n",
    "# CREATE DICTIONARIES IN WHICH TO STORE CALCULATED VALUES\n",
    "first_dict = {}\n",
    "mean_dict = {}\n",
    "med_dict = {}\n",
    "std_dict = {}\n",
    "skew_dict = {}\n",
    "kurt_dict = {}\n",
    "min_dict = {}\n",
    "max_dict = {}\n",
    "slope_dict = {}\n",
    "delta_dict = {}\n",
    "abnflag_dict = {}\n",
    "dict_list = [first_dict, mean_dict, med_dict, std_dict, skew_dict, min_dict, max_dict, slope_dict, delta_dict,\n",
    "            abnflag_dict]\n",
    "calc_dict = dict(zip(calc_list, dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# iterating through the lab measurements for each ICU stay, calculating means, medians, std, skewness min and max\n",
    "# lab measurements within an ICU stay with too few measurements to calculate feature will be assigned NaN values\n",
    "\n",
    "print(\"Creating data frames for each summary statistic for each time course variable\")\n",
    "for calc_key in calc_dict.keys():\n",
    "    for col_key in names_dict[calc_key].keys(): \n",
    "        if calc_key == 'mean':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].mean())\n",
    "        elif calc_key == 'med':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].median())\n",
    "        elif calc_key == 'std':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].std())\n",
    "        elif calc_key == 'max':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].max())\n",
    "        elif calc_key == 'min':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].min())\n",
    "        elif calc_key == 'first': \n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].first())\n",
    "        elif calc_key == 'skew':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].skew())\n",
    "        elif calc_key == 'delta': \n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].last() -\n",
    "                                                        lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].first())\n",
    "        elif calc_key == 'abnflag':\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame(lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['flag'].apply(lambda x: int(1) if 'abnormal' in x.values else int(0)))\n",
    "              \n",
    "        elif calc_key == 'slope':\n",
    "            time_last = lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['charttime'].last()\n",
    "            time_first = lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['charttime'].first()\n",
    "            val_last = lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].last()\n",
    "            val_first = lab_events_data_df[lab_events_data_df.label == names_dict[calc_key][col_key]].groupby('icustay_id')['valuenum'].first()\n",
    "            calc_dict[calc_key][col_key] = pd.DataFrame((val_last - val_first)/((time_last - time_first)/np.timedelta64(1,'h')))           \n",
    "        \n",
    "            \n",
    "        else: \n",
    "            print(\"need to add code for calculating {}\".format(calc_key))\n",
    "            break\n",
    "            \n",
    "        calc_dict[calc_key][col_key].replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "        calc_dict[calc_key][col_key].columns = [col_key]\n",
    "        calc_dict[calc_key][col_key]['hospital_expire_flag'] = lab_events_data_df.groupby('icustay_id').hospital_expire_flag.first()\n",
    "        calc_dict[calc_key][col_key]['gender'] = lab_events_data_df.groupby('icustay_id').gender.first()\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# PLOTTING DATA FOR EXAMPLE FRAME\n",
    "#mean_dict[mean_dict.keys()[0]].head()\n",
    "dummy = calc_dict['mean']\n",
    "\n",
    "for col in dummy.keys():\n",
    "    \n",
    "    col2 = dummy[col].columns[0]\n",
    "    \n",
    "    \n",
    "    gender = ['M', 'F'] \n",
    "    \n",
    "    for gend in gender:\n",
    "        \n",
    "        #print gend\n",
    "        dead = dummy[col][(dummy[col].hospital_expire_flag == 1)&\n",
    "                              (dummy[col].gender == gend)]\n",
    "                          #&(const_dict[col][col2] >20)]\n",
    "        dead.name = 'Non_Survivors'\n",
    "        live = dummy[col][(dummy[col].hospital_expire_flag == 0)&\n",
    "                              (dummy[col].gender == gend)]\n",
    "                          #&(const_dict[col][col2] >20)]\n",
    "        live.name = 'Survivors'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #dummy = mean_dict[key][mean_dict[key].gender == 'F']\n",
    "    #dummy = skew_dict[key].merge(pd.DataFrame(ptnt_demog['hospital_expire_flag']), \n",
    "    #                                   left_index = True, right_index = True, how='left', sort = True)\n",
    "    \n",
    "        maxx = 0.99\n",
    "        minn = 0.01\n",
    "    \n",
    "        live_max = live[col2].dropna().max()#quantile(0.999)\n",
    "        live_min = live[col2].dropna().min()#quantile(0.001)\n",
    "        dead_max = dead[col2].dropna().max()#quantile(0.999)\n",
    "        dead_min = dead[col2].dropna().min()#quantile(0.001)\n",
    "        maxlim = max(live_max, dead_max)\n",
    "        minlim = min(live_min, dead_min)\n",
    "   \n",
    "        \n",
    "        plt.subplots(figsize=(10,4))\n",
    "        live[(live[col2] < live_max) & (live[col2] > live_min)][col2].plot.kde(\n",
    "                                                                            alpha=1.0,label='Survival')\n",
    "    \n",
    "        dead[(dead[col2] < dead_max) & (dead[col2] > dead_min)][col2].plot.kde(\n",
    "                                                                            alpha=1.0,label='Non-Survivors')\n",
    "        # add title, labels etc.\n",
    "        plt.title('{} measurement on ICU admission'.format(col) + \n",
    "                   'vs ICU mortality by gender = {}\\n'.format(gend))\n",
    "        plt.xlabel(col)\n",
    "        plt.legend(loc=\"upper left\", bbox_to_anchor=(.75,.75),fontsize=12)\n",
    "   \n",
    "    \n",
    "        #print \"{}    {}\".format(maxlim, minlim)\n",
    "        plt.xlim(minlim, maxlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE OUTLIER DATA POINTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "names_dict = {}\n",
    "suffix = '_outliers'\n",
    "\n",
    "# SETTING OUTLIER DATA POINTS TO NAN FOR REMOVAL USING DROPNA()\n",
    "for calc in calc_dict.keys():\n",
    "    frame = calc_dict[calc]\n",
    "    for col in frame.keys():\n",
    "    # plot\n",
    "    # print col\n",
    "        dummy = frame[col]\n",
    "        col2 = dummy.columns[0]\n",
    "        #print \"{}   {}     {}\".format(col, col2, dummy.dropna().shape)\n",
    "        Q1 = np.percentile(dummy[col2].dropna(), 25)\n",
    "        # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "        Q3 = np.percentile(dummy[col2].dropna(), 75)\n",
    "        # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "        step = 1.5*(Q3 - Q1)\n",
    "        names_dict[col+suffix] = dummy[~((dummy[col2] >= Q1 - step) & (dummy[col2] <= Q3 + step))].index\n",
    "#         dummy.set_value(names_dict[col+suffix], col2, np.NaN)\n",
    "#         dummy.set_value(names_dict[col+suffix], col2, np.NaN)\n",
    "        dummy.loc[names_dict[col+suffix], col2] = np.NaN\n",
    "        #print \"{}   {}     {}\".format(col, col2, dummy.dropna().shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict[col+suffix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT DATA WITH OUTLIERS REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# PLOTTING DATA FOR EXAMPLE FRAME\n",
    "#mean_dict[mean_dict.keys()[0]].head()\n",
    "dummy = calc_dict['min']\n",
    "\n",
    "for col in dummy.keys():\n",
    "    \n",
    "    col2 = dummy[col].columns[0]\n",
    "    \n",
    "    \n",
    "    gender = ['M', 'F'] \n",
    "    \n",
    "    for gend in gender:\n",
    "        \n",
    "        #print gend\n",
    "        dead = dummy[col][(dummy[col].hospital_expire_flag == 1)&\n",
    "                              (dummy[col].gender == gend)]\n",
    "                          #&(const_dict[col][col2] >20)]\n",
    "        dead.name = 'Non_Survivors'\n",
    "        live = dummy[col][(dummy[col].hospital_expire_flag == 0)&\n",
    "                              (dummy[col].gender == gend)]\n",
    "                          #&(const_dict[col][col2] >20)]\n",
    "        live.name = 'Survivors'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #dummy = mean_dict[key][mean_dict[key].gender == 'F']\n",
    "    #dummy = skew_dict[key].merge(pd.DataFrame(ptnt_demog['hospital_expire_flag']), \n",
    "    #                                   left_index = True, right_index = True, how='left', sort = True)\n",
    "    \n",
    "        maxx = 0.99\n",
    "        minn = 0.01\n",
    "    \n",
    "        live_max = live[col2].dropna().max()#quantile(0.999)\n",
    "        live_min = live[col2].dropna().min()#quantile(0.001)\n",
    "        dead_max = dead[col2].dropna().max()#quantile(0.999)\n",
    "        dead_min = dead[col2].dropna().min()#quantile(0.001)\n",
    "        maxlim = max(live_max, dead_max)\n",
    "        minlim = min(live_min, dead_min)\n",
    "   \n",
    "        \n",
    "        plt.subplots(figsize=(10,4))\n",
    "        live[(live[col2] < live_max) & (live[col2] > live_min)][col2].plot.kde(\n",
    "                                                                            alpha=1.0,label='Survival')\n",
    "    \n",
    "        dead[(dead[col2] < dead_max) & (dead[col2] > dead_min)][col2].plot.kde(\n",
    "                                                                            alpha=1.0,label='Non-Survivors')\n",
    "        # add title, labels etc.\n",
    "        plt.title('{} measurement on ICU admission'.format(col) + \n",
    "                   'vs ICU mortality by gender = {}\\n'.format(gend))\n",
    "        plt.xlabel(col)\n",
    "        plt.legend(loc=\"upper left\", bbox_to_anchor=(0.75,0.75),fontsize=12)\n",
    "   \n",
    "    \n",
    "        #print \"{}    {}\".format(maxlim, minlim)\n",
    "        #plt.xlim(minlim, maxlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE INDIVIDUAL DATAFRAMES INTO SINGLE FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MERGING INDIVIDUAL CALCULATED FRAMES INTO A SINGLE DATAFRAMEs\n",
    "lab_events_data_df2 = lab_events_data_df.drop_duplicates('icustay_id', keep = 'first')\n",
    "lab_events_data_df3 = lab_events_data_df2.drop(['label', 'charttime', 'valuenum', 'flag'], axis = 1)\n",
    "lab_events_data_df3.set_index(['icustay_id'], inplace = True)\n",
    "\n",
    "for calc_key in calc_dict.keys():\n",
    "    print(\"merging {} dataframe\".format(calc_key))\n",
    "    for col_key in calc_dict[calc_key].keys(): \n",
    "        col2 = calc_dict[calc_key][col_key]\n",
    "        lab_events_data_df3 = lab_events_data_df3.merge(pd.DataFrame(calc_dict[calc_key][col_key][col_key]), left_index = True, \n",
    "                           right_index = True, how = 'left', sort = True)\n",
    "        newcols = list(lab_events_data_df3.columns)\n",
    "        newcols.pop()\n",
    "        newcols.append(col_key)\n",
    "        lab_events_data_df3.columns = newcols\n",
    "display(lab_events_data_df3.shape)\n",
    "display(lab_events_data_df3.head())\n",
    "display(lab_events_data_df3.dtypes)\n",
    "        \n",
    "# OLD CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in lab_events_data_df3.columns if calc in x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cols = [\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df3['Creat_abnflag'].head(25).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df3['Creat_abnflag'].head(25).apply(lambda x: 1 if x==1.0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Boolean Cols to INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in lab_events_data_df3.columns if calc in x]\n",
    "for col in cols: \n",
    "    lab_events_data_df3[col] = lab_events_data_df3[col].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Versions Didn't Fully Leverage Interpolation\n",
    "As Such, efforts below were made to found labs most commonly found together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for labs that are commonly missing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ROUNDING DATA\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# cols = [x for x in lab_events_data_df3.columns if calc in x] \n",
    "# cols.sort()\n",
    "    \n",
    "# header = lab_events_data_df3[cols]\n",
    "# for col in header.columns:\n",
    "#     header[col] = header[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "# display(lab_events_data_df3[cols].dropna().shape[0])\n",
    "\n",
    "# display(header.corr().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISPLAY COLORMAP OF MISSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# commenting out for refinement. \n",
    "# very time consuming part of pre-processing. uncomment and run if you'd like to see the process. \n",
    "\n",
    "\n",
    "'''\n",
    "# DISPLAY COLORMAP OF DATA \n",
    "\n",
    "for calc in calc_list:\n",
    "    plt.figure(figsize= (30,30))\n",
    "    cols = [x for x in data3.columns if calc in x] \n",
    "    cols.sort()\n",
    "    \n",
    "    header = data3[cols]\n",
    "    for col in header.columns:\n",
    "        max_val = -1000 #header[col].max()*100\n",
    "        #header[col].replace(np.nan, max_val, inplace = True)\n",
    "        header[col] = header[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    display(data3[cols].dropna().shape[0])\n",
    "    missing = header.corr()\n",
    "    display(missing[missing >= 0.4])\n",
    "    plt.pcolor(header)\n",
    "    plt.xticks(np.arange(0.5, len(header.columns), 1), header.columns)\n",
    "    plt.show()\n",
    "\n",
    "print \"Complete\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE AUTOCORRELATION MATRIX FOR MISSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #header.apply(lambda col: col.autocorr(lag = 1), axis = 0)\n",
    "# # REPLACING NAN VALUES WITH 1 AND MEASUREMENTS WITH 0. PERFORMING CORRELATION BETWEEN COLUMNS TO DETERMINE WHICH \n",
    "# # VARIABLES ARE MOST LIKELY TO BE MISSING TOGETHER. THIS WILL HELP IN BLOCKING DATA FOR PROCESSES THAT REQUIRE DATA TO \n",
    "# # BE NAN FREE\n",
    "# missing = lab_events_data_df3.copy()\n",
    "# for col in missing.columns:\n",
    "#     missing[col] = missing[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        \n",
    "# monkey = missing.corr()\n",
    "# monkey[monkey >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# DROPPING COLUMNS WHERE DATA IS SPARSE AND MISSING DATA DOES NOT CORRELATE WITH OTHER VARIABLES. \n",
    "# THESE DETERMINATIONS WERE MADE THROUGH OBSERVATIONS OF THE AFFINITY MAPS AND DROPNA().SHAPE[0] VALUES ABOVE \n",
    "\n",
    "# REMOVING ALL CREATURINE MEASURES\n",
    "drop_cols = []\n",
    "for item in lab_events_data_df3.columns: \n",
    "    if (('CreatUrine'in item) | ('LacDehyd' in item) | ('_skew' in item)):\n",
    "        drop_cols.append(item)\n",
    "#drop_cols\n",
    "\n",
    "# DROP THE FOLLOWING MEASURES OF THE FOLLOWING VARIABLES\n",
    "#drop_names = ['CreatUrine', 'LacDehyd', 'O2sat', 'Lac']\n",
    "drop_names = ['O2sat', 'Lac']\n",
    "drop_measures = ['_std', '_slope']\n",
    "for name in drop_names:\n",
    "    for ext in drop_measures:\n",
    "        drop_cols.append(name + ext)\n",
    "        \n",
    "drop_cols\n",
    "        \n",
    "\n",
    "display(lab_events_data_df3.dropna().shape[0])\n",
    "lab_events_data_df4 = lab_events_data_df3.drop(drop_cols, inplace = False, axis = 1)\n",
    "display(lab_events_data_df4.dropna().shape[0])\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING FRAMES AND DROPPING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # TO THIS POINT THE ICUSTAY_ID HAS BEEN USED AS THE INDEX OF THE DATAFRAME. \n",
    "# # TO USE THESE METHODS WE CREATE A PROPER INDEX\n",
    "\n",
    "\n",
    "# # BREAKING UP VARIABLES SO THAT WE CAN DROP NAN VALUES AND STILL HAVE SUFFICIENT SAMPLES \n",
    "# # TO TRANSFORM AND DO FEATURE SELECTION / SCORING\n",
    "# # WILL NEED TO MERGE LATER IN A WAY THAT PROVIDES ADEQUATE SAMPLES\n",
    "\n",
    "# cols1 = [x for x in data4.columns if (('abnflag' not in x) & (('pH' in x) | ('Lac' in x) | ('O2sat' in x)))]\n",
    "# cols2 = [x for x in data4.columns if (('abnflag' not in x) & (('Creat' in x) | ('Gluc' in x) | ('Hemat' in x) | ('WBC' in x)))]\n",
    "# cols3 = [x for x in data4.columns if ('abnflag' in x)]\n",
    "\n",
    "# header = ['hospital_expire_flag']\n",
    "# for thing in header:\n",
    "#     cols1.insert(0, thing)\n",
    "#     cols2.insert(0, thing) \n",
    "#     cols3.insert(0, thing)\n",
    "  \n",
    "\n",
    "# #display(cols1)\n",
    "# data4.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "# pHLacO2Sat_data = data4[cols1].dropna()\n",
    "# print \"pHLacO2Sat_data: Shape = \"\n",
    "# display(pHLacO2Sat_data.shape)                              \n",
    "\n",
    "# CreatGlucHemWBC_data = data4[cols2].dropna()\n",
    "# print \"CreatGlucHemWBC_data: Shape = \"\n",
    "# display(CreatGlucHemWBC_data.shape)\n",
    "\n",
    "# AbnFlag_data = data4[cols3].dropna()\n",
    "# print \"AbnFlag_data: Shape = \"\n",
    "# display(AbnFlag_data.shape)\n",
    "\n",
    "       \n",
    "# cont_frames = [pHLacO2Sat_data, CreatGlucHemWBC_data]\n",
    "# cat_frames = [AbnFlag_data]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df4.replace([np.inf, -np.inf], np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lab_events_data_df4[lab_events_data_df4.columns[3:]]\n",
    "# imp_iter = IterativeImputer(missing_values = np.nan, max_iter=100, add_indicator=True)\n",
    "imp_iter = SimpleImputer(missing_values = np.nan, add_indicator=False)\n",
    "imp_iter.fit(X)\n",
    "imputed_data_df = imp_iter.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df4[lab_events_data_df4.columns[3:]] = imputed_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERTING CONTINUOUS TO CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_data_df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CALCULATING THE QUARTILES ON THE DISTRIBUTIONS AND BINNING DATA INTO 4 BUCKETS\n",
    "# TO CONVERT CONTINUOUS VARIABLES TO CATEGORICAL\n",
    "\n",
    "def quant_cats(feature, Q1, Q2, Q3):\n",
    "    if feature <=Q1:\n",
    "        return 'Q0'\n",
    "    elif (feature >Q1 and feature <= Q2):\n",
    "        return 'Q1'\n",
    "    elif (feature > Q2 and feature <= Q3):\n",
    "        return 'Q2'\n",
    "    elif feature > Q3:\n",
    "        return 'Q3'\n",
    "    \n",
    "#cont_frames = [pHLacO2Sat_data, CreatGlucHemWBC_data]\n",
    "#cat_frames = [AbnFlag_data]\n",
    "    \n",
    "CreatGlucHemWBC_cat_data = CreatGlucHemWBC_data.copy()\n",
    "pHLacO2Sat_cat_data = pHLacO2Sat_data.copy()\n",
    "\n",
    "cont_cat_frames = [CreatGlucHemWBC_cat_data, pHLacO2Sat_cat_data]\n",
    "\n",
    "for frame in cont_cat_frames:\n",
    "    frame_stats = frame.describe()\n",
    "    for col in frame.columns[1:]:\n",
    "        Q1 = frame_stats[col].loc['25%']\n",
    "        Q2 = frame_stats[col].loc['50%']\n",
    "        Q3 = frame_stats[col].loc['75%']\n",
    "        frame[col] = frame[col].apply(lambda x: quant_cats(x, Q1, Q2, Q3))\n",
    "\n",
    "pHLacO2Sat_cat_data.head()        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cont_cat_frames = [CreatGlucHemWBC_cat_data, pHLacO2Sat_cat_data]\n",
    "\n",
    "\n",
    "pHLacO2Sat_dummies = pHLacO2Sat_cat_data[pHLacO2Sat_cat_data.columns[:1]].merge(pd.get_dummies(pHLacO2Sat_cat_data[pHLacO2Sat_cat_data.columns[3:]]), left_index = True, right_index = True, \n",
    "                       how = 'left', sort = True)\n",
    "CreatGlucHemWBC_dummies = CreatGlucHemWBC_cat_data[CreatGlucHemWBC_cat_data.columns[:1]].merge(pd.get_dummies(CreatGlucHemWBC_cat_data[CreatGlucHemWBC_cat_data.columns[3:]]), left_index = True, right_index = True, \n",
    "                       how = 'left', sort = True)\n",
    "                       \n",
    "display(pHLacO2Sat_dummies.head())\n",
    "display(CreatGlucHemWBC_dummies.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERT DATA TO DUMMY VARIABLES, RECOMBINE, SELECT BEST FEATURES WRITE TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_frames = [CreatGlucHemWBC_dummies, pHLacO2Sat_dummies, AbnFlag_data]\n",
    "dummy_frame_filenames = ['Lab_CreatGlucHemWBC_Features', 'Lab_pHLacO2Sat_Features', 'Lab_AbnFlag_Features']\n",
    "dummy_dict = dict(zip(dummy_frame_filenames, dummy_frames))\n",
    "\n",
    "for name, frame in dummy_dict.iteritems():\n",
    "    print \"{}      {}\".format(name, frame.shape[0])\n",
    "\n",
    "# CREATGLUC ETC HAS ONLY 874 SAMPLES AND SO WON'T BE HELPFUL. \n",
    "\n",
    "root = os.getcwd() + '/features/'\n",
    "\n",
    "for name, frame in dummy_dict.iteritems():#frame = cat_dummy_frames[0]\n",
    "    X_continuous = frame[frame.columns[1:]]\n",
    "    y = frame['hospital_expire_flag']\n",
    "    #display(X_continuous.shape)\n",
    "    #display(y.shape)\n",
    "    # ONLY PASSING FRAMES W/ > 5000 ICUSTAYS\n",
    "    if y.shape[0] > 3000:\n",
    "        \n",
    "        # SELECT K BEST FEATURES BASED ON CHI2 SCORES\n",
    "        selector = SelectKBest(score_func = chi2, k = 'all')\n",
    "        selector.fit(X_continuous, y)\n",
    "        p_vals = pd.Series(selector.pvalues_, name = 'p_values', index = X_continuous.columns)\n",
    "        scores = pd.Series(selector.scores_, name = 'scores', index = X_continuous.columns)\n",
    "        cont_features_df = pd.concat([p_vals, scores], axis = 1)\n",
    "        cont_features_df.sort_values(by ='scores', ascending = False, inplace = True)\n",
    "        best_features = frame[cont_features_df[cont_features_df.p_values < .001].index]\n",
    "        frame = pd.DataFrame(y).merge(best_features, left_index = True, right_index = True, \n",
    "                       how = 'left', sort = True)\n",
    "        print \"{}     {}\".format(name, frame.shape)\n",
    "        frame.to_csv(root + name + '.csv')\n",
    "        cont_features_df[cont_features_df.p_values < .001].to_csv(root + name + 'Scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
